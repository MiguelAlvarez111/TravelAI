"""
Servicio de integraciÃ³n con Google Gemini para recomendaciones de viaje.
"""
import os
import logging
import traceback
from typing import Optional, List, Dict
import google.generativeai as genai
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logger = logging.getLogger(__name__)

# System Prompt para Gemini - Plan Inicial de Viaje
# InstrucciÃ³n de sistema para cuando el usuario solicita un plan completo de viaje
SYSTEM_INSTRUCTION_PLAN = """Eres Alex, el consultor de viajes mÃ¡s experto y entusiasta del mundo.

REGLAS DE ORO:
1. RESPONDER ÃšNICAMENTE EN ESPAÃ‘OL. Nunca uses otros idiomas como Hindi, InglÃ©s, FrancÃ©s, etc. Todo el contenido debe estar en espaÃ±ol.
2. Tu respuesta SIEMPRE debe usar formato Markdown.
3. Tu respuesta DEBE tener EXACTAMENTE estas 5 secciones (usa estos tÃ­tulos con emojis):

## ðŸ¨ ALOJAMIENTO IDEAL

## ðŸ¥˜ GASTRONOMÃA IMPERDIBLE

## ðŸ’Ž LUGARES CLAVE

## ðŸ’¡ CONSEJOS DE ALEX

## ðŸ’° ESTIMACIÃ“N DE COSTOS

4. SÃ© entusiasta, profesional y detallado en cada secciÃ³n.
5. Usa emojis apropiados para hacer la informaciÃ³n mÃ¡s atractiva.
6. AsegÃºrate de incluir TODAS las 5 secciones en tu respuesta.
7. Si detectas que estÃ¡s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y continÃºa en espaÃ±ol."""

# System Prompt para Gemini - Chat Conversacional
# InstrucciÃ³n de sistema para preguntas de seguimiento en el chat
SYSTEM_INSTRUCTION_CHAT = """Eres Alex, el consultor de viajes mÃ¡s experto y entusiasta del mundo.

REGLAS DE ORO:
1. RESPONDER ÃšNICAMENTE EN ESPAÃ‘OL. Nunca uses otros idiomas como Hindi, InglÃ©s, FrancÃ©s, etc. Todo el contenido debe estar en espaÃ±ol.
2. Tu respuesta debe usar formato Markdown para mejorar la legibilidad.
3. Responde de manera NATURAL y CONVERSACIONAL. No fuerces estructuras rÃ­gidas.
4. Si el usuario hace una pregunta especÃ­fica (ej: "Â¿Es seguro?", "Â¿QuÃ© restaurantes recomiendas?"), responde directamente a esa pregunta de forma clara y detallada.
5. Solo usa las secciones estructuradas (ðŸ¨ ALOJAMIENTO, ðŸ¥˜ GASTRONOMÃA, etc.) si el usuario explÃ­citamente pide un "plan completo" o "plan de viaje". Para preguntas de seguimiento, responde de forma conversacional.
6. SÃ© entusiasta, profesional y detallado.
7. Usa emojis apropiados cuando sea natural, pero no fuerces su uso.
8. Si detectas que estÃ¡s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y continÃºa en espaÃ±ol.
9. MantÃ©n el contexto del viaje que el usuario estÃ¡ planificando."""


class GeminiService:
    """Servicio para interactuar con Google Gemini API."""
    
    def __init__(self):
        """Inicializa el servicio de Gemini y valida la API key."""
        self.api_key = os.getenv("GEMINI_API_KEY")
        
        if not self.api_key:
            raise ValueError(
                "âŒ ERROR: GEMINI_API_KEY no encontrada en variables de entorno. "
                "Por favor, crea un archivo .env con tu API key de Google Gemini."
            )
        
        # Configurar la API key
        genai.configure(api_key=self.api_key)
        
        # Inicializar el modelo usando gemini-2.0-flash (gemini-1.5-flash no estÃ¡ disponible)
        # ConfiguraciÃ³n del modelo usando os.getenv para la API Key (ya configurada arriba)
        try:
            self.model = genai.GenerativeModel(model_name='gemini-2.0-flash')
            logger.info("âœ… Servicio de Gemini inicializado correctamente con gemini-2.0-flash")
        except Exception as e:
            logger.error(f"âŒ Error al inicializar el modelo de Gemini: {e}")
            raise
    
    def generate_travel_recommendation(
        self, 
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = ""
    ) -> str:
        """
        Genera una recomendaciÃ³n de viaje usando Gemini con campos estructurados.
        
        Args:
            destination: El destino del viaje (obligatorio)
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            
        Returns:
            str: RecomendaciÃ³n de viaje formateada en Markdown con las 5 secciones estrictas
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Validar argumentos antes de construir el prompt
            if not destination or not destination.strip():
                raise ValueError("El destino no puede estar vacÃ­o")
            
            destination = destination.strip()
            date = date.strip() if date else ""
            budget = budget.strip() if budget else ""
            style = style.strip() if style else ""
            
            logger.info(f"ðŸ“¤ Generando recomendaciÃ³n de viaje - Destino: '{destination}', Fecha: '{date}', Presupuesto: '{budget}', Estilo: '{style}'")
            
            # Construir el prompt combinando los 4 campos en una frase coherente
            prompt_parts = [f"Planifica un viaje a {destination}"]
            
            if date:
                prompt_parts.append(f"para la fecha {date}")
            
            if budget:
                prompt_parts.append(f"con presupuesto {budget}")
            
            if style:
                prompt_parts.append(f"y estilo {style}")
            
            # Combinar todas las partes en una frase coherente
            user_request = " ".join(prompt_parts) + "."
            
            # Construir el prompt completo incluyendo el system instruction para PLAN
            # La instrucciÃ³n de sistema se inyecta antes de la pregunta del usuario
            full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}\n\n---\n\nSolicitud del usuario: {user_request}"
            
            # Generar respuesta usando Gemini
            # Esta es la llamada a la API de Google Gemini que envÃ­a la pregunta del usuario
            logger.info(f"ðŸ”„ Enviando solicitud a Gemini: {user_request[:100]}...")
            logger.debug(f"ðŸ“ Longitud del prompt completo: {len(full_prompt)} caracteres")
            
            response = self.model.generate_content(full_prompt)
            
            # Extraer el texto de la respuesta
            if not response or not hasattr(response, 'text') or not response.text:
                raise ValueError("La respuesta de Gemini estÃ¡ vacÃ­a o no tiene texto")
            
            recommendation = response.text
            
            logger.info(f"âœ… RecomendaciÃ³n generada exitosamente por Alex ({len(recommendation)} caracteres)")
            return recommendation
            
        except ValueError as e:
            # Errores de validaciÃ³n o configuraciÃ³n
            logger.error(f"âŒ Error de validaciÃ³n en Gemini: {e}")
            logger.error(f"ðŸ“‹ Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraciÃ³n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"âŒ Error al consultar Gemini: {error_type}: {error_message}")
            logger.error(f"ðŸ“‹ Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"ðŸ” Argumentos recibidos: destination='{destination}', date='{date}', budget='{budget}', style='{style}'")
            raise Exception("OcurriÃ³ un error consultando a la IA")
    
    def generate_chat_response(
        self,
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = "",
        message: str = "",
        history: List[Dict] = []
    ) -> str:
        """
        Genera una respuesta de chat usando Gemini con memoria conversacional.
        
        Esta funciÃ³n inyecta el contexto del viaje (destino, fecha, presupuesto, estilo) y
        la personalidad de Alex (consultor de viajes experto y entusiasta) mediante un
        system prompt especializado para conversaciones (SYSTEM_INSTRUCTION_CHAT).
        
        El historial de conversaciÃ³n se limita a los Ãºltimos 6 mensajes para optimizar
        el uso de tokens y mantener el contexto relevante. Si hay historial, se construye
        un prompt que incluye el contexto del viaje, el historial de conversaciÃ³n y el
        nuevo mensaje del usuario. Si no hay historial, se trata como una solicitud inicial
        y se usa SYSTEM_INSTRUCTION_PLAN.
        
        Args:
            destination: El destino del viaje
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            message: El nuevo mensaje del usuario
            history: Lista de mensajes anteriores en formato [{"role": "user", "parts": "..."}, ...]
            
        Returns:
            str: Respuesta de Gemini formateada en Markdown
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Construir el contexto del viaje
            context_info = f"Contexto del viaje: Destino: {destination}"
            if date:
                context_info += f", Fecha: {date}"
            if budget:
                context_info += f", Presupuesto: {budget}"
            if style:
                context_info += f", Estilo: {style}"
            
            # Si hay historial, construir el prompt con el historial concatenado
            if history:
                # Construir el historial como texto para el contexto
                history_text = "\n\n--- Historial de ConversaciÃ³n ---\n\n"
                for msg in history:
                    role_label = "Usuario" if msg.get("role") == "user" else "Alex"
                    history_text += f"{role_label}: {msg.get('parts', '')}\n\n"
                
                # Construir el prompt completo con historial usando SYSTEM_INSTRUCTION_CHAT
                # Para preguntas de seguimiento, usa la instrucciÃ³n conversacional
                full_prompt = f"{SYSTEM_INSTRUCTION_CHAT}\n\n---\n\n{context_info}\n\n{history_text}---\n\nUsuario pregunta ahora: {message}"
                
                logger.info(f"Enviando mensaje de chat a Gemini con historial de {len(history)} mensajes")
            else:
                # Si no hay historial, es el primer mensaje - usar SYSTEM_INSTRUCTION_PLAN
                prompt_parts = [f"Planifica un viaje a {destination}"]
                
                if date:
                    prompt_parts.append(f"para la fecha {date}")
                
                if budget:
                    prompt_parts.append(f"con presupuesto {budget}")
                
                if style:
                    prompt_parts.append(f"y estilo {style}")
                
                user_request = " ".join(prompt_parts) + "."
                full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}\n\n---\n\n{context_info}\n\nSolicitud del usuario: {user_request}"
                
                logger.info(f"Enviando solicitud inicial a Gemini: {destination}")
            
            # Generar respuesta usando Gemini
            response = self.model.generate_content(full_prompt)
            recommendation = response.text
            logger.info("âœ… Respuesta generada exitosamente por Alex")
            return recommendation
            
        except ValueError as e:
            # Errores de validaciÃ³n o configuraciÃ³n
            logger.error(f"âŒ Error de validaciÃ³n en Gemini (chat): {e}")
            logger.error(f"ðŸ“‹ Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraciÃ³n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"âŒ Error al consultar Gemini (chat): {error_type}: {error_message}")
            logger.error(f"ðŸ“‹ Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"ðŸ” Argumentos recibidos: destination='{destination}', message='{message[:50]}...', history_length={len(history)}")
            raise Exception("OcurriÃ³ un error consultando a la IA")


# Instancia global del servicio (se inicializa al importar)
_gemini_service: Optional[GeminiService] = None


def get_gemini_service() -> GeminiService:
    """
    Obtiene la instancia singleton del servicio de Gemini.
    
    Returns:
        GeminiService: Instancia del servicio
    """
    global _gemini_service
    
    if _gemini_service is None:
        _gemini_service = GeminiService()
    
    return _gemini_service

