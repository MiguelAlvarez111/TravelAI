"""
Servicio de integraci√≥n con Google Gemini para recomendaciones de viaje.
"""
import os
import logging
import traceback
import re
from typing import Optional, List, Dict, Tuple
import google.generativeai as genai
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logger = logging.getLogger(__name__)


def sanitize_input(text: str, max_length: int = 500) -> Tuple[bool, str]:
    """
    Sanitiza y valida el input del usuario para prevenir prompt injection.
    
    Esta funci√≥n detecta patrones maliciosos comunes en intentos de prompt injection
    y valida la longitud del input para prevenir payloads gigantes.
    
    Args:
        text: Texto a sanitizar
        max_length: Longitud m√°xima permitida (default: 500 caracteres)
        
    Returns:
        Tuple[bool, str]: (es_v√°lido, mensaje_error)
        - Si es_v√°lido es True, el texto es seguro
        - Si es_v√°lido es False, mensaje_error contiene la raz√≥n del rechazo
    """
    if not text or not isinstance(text, str):
        return False, "El texto no puede estar vac√≠o"
    
    # Normalizar el texto (min√∫sculas para comparaci√≥n case-insensitive)
    text_lower = text.lower().strip()
    
    # Verificar longitud m√°xima
    if len(text) > max_length:
        return False, f"El texto excede la longitud m√°xima permitida de {max_length} caracteres"
    
    # Patrones maliciosos comunes de prompt injection (ingl√©s y espa√±ol)
    malicious_patterns = [
        # Intentos de ignorar instrucciones (ingl√©s)
        r"(?i)ignore\s+(your|all|previous|earlier|prior)\s+(instructions?|prompts?|rules?|directives?|guidelines?)",
        r"(?i)forget\s+(everything|all|previous|earlier|prior)",
        r"(?i)disregard\s+(your|all|previous|earlier)\s+(instructions?|prompts?|rules?)",
        r"(?i)override\s+(your|system|previous)\s+(instructions?|prompts?|rules?)",
        r"(?i)ignore\s+(your|all|previous|earlier|prior)",
        # Intentos de ignorar instrucciones (espa√±ol)
        r"(?i)ignora\s+(tus|todas|las|tus\s+instrucciones|tus\s+reglas)",
        r"(?i)olvida\s+(todo|todas|las|tus|instrucciones)",
        r"(?i)desobedece\s+(tus|las|instrucciones|reglas)",
        r"(?i)anula\s+(tus|las|instrucciones|reglas)",
        
        # Intentos de cambiar el rol o comportamiento (ingl√©s)
        r"(?i)you\s+are\s+now\s+(a|an|the)",
        r"(?i)act\s+as\s+(if\s+)?(you\s+are\s+)?(a|an|the)",
        r"(?i)pretend\s+(to\s+be|you\s+are|that\s+you)",
        r"(?i)roleplay\s+(as|that)",
        # Intentos de cambiar el rol o comportamiento (espa√±ol)
        r"(?i)eres\s+ahora\s+(un|una|el|la)",
        r"(?i)act√∫a\s+(como|si\s+eres|si\s+fu eras)",
        r"(?i)finge\s+(ser|que\s+eres|que)",
        r"(?i)hazte\s+pasar\s+por",
        
        # Intentos de acceso a instrucciones del sistema (ingl√©s)
        r"(?i)system\s*:",
        r"(?i)system\s+prompt",
        r"(?i)system\s+instruction",
        r"(?i)assistant\s*:",
        r"(?i)ai\s+instruction",
        # Intentos de acceso a instrucciones del sistema (espa√±ol)
        r"(?i)sistema\s*:",
        r"(?i)prompt\s+del\s+sistema",
        r"(?i)instrucciones\s+del\s+sistema",
        r"(?i)asistente\s*:",
        r"(?i)mu√©strame\s+(tus|las|el)\s+(instrucciones|prompt|reglas)",
        
        # Intentos de extraer informaci√≥n del sistema
        r"(?i)show\s+(me\s+)?(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)what\s+(are\s+)?(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)reveal\s+(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)print\s+(your|the)\s+(instructions|prompt|system|rules)",
        
        # Intentos de ejecutar comandos
        r"(?i)(execute|run|eval|exec)\s*[:(]",
        r"(?i)<script",
        r"(?i)javascript\s*:",
        
        # Intentos de inyecci√≥n de c√≥digo
        r"(?i)(import|from)\s+\w+\s+import",
        r"(?i)__import__",
        r"(?i)subprocess",
    ]
    
    # Verificar cada patr√≥n
    for pattern in malicious_patterns:
        if re.search(pattern, text_lower):
            logger.warning(f"‚ö†Ô∏è  Intento de prompt injection detectado: {text[:100]}...")
            return False, "El contenido contiene patrones no permitidos. Por favor, reformula tu solicitud."
    
    # Si pasa todas las validaciones, el texto es seguro
    return True, ""

# System Prompt para Gemini - Plan Inicial de Viaje
# Instrucci√≥n de sistema para cuando el usuario solicita un plan completo de viaje
SYSTEM_INSTRUCTION_PLAN = """Eres Alex, el consultor de viajes m√°s experto y entusiasta del mundo.

REGLAS DE ORO:
1. RESPONDER √öNICAMENTE EN ESPA√ëOL. Nunca uses otros idiomas como Hindi, Ingl√©s, Franc√©s, etc. Todo el contenido debe estar en espa√±ol.
2. Tu respuesta SIEMPRE debe usar formato Markdown.
3. Tu respuesta DEBE tener EXACTAMENTE estas 5 secciones (usa estos t√≠tulos con emojis):

## üè® ALOJAMIENTO IDEAL

## ü•ò GASTRONOM√çA IMPERDIBLE

## üíé LUGARES CLAVE

## üí° CONSEJOS DE ALEX

## üí∞ ESTIMACI√ìN DE COSTOS
   - Proporciona los costos principales en USD (d√≥lares estadounidenses).
   - Si el usuario tiene una moneda diferente, incluye tambi√©n la conversi√≥n aproximada en su moneda local.
   - Formato: "$100 USD (~400,000 COP)" o similar seg√∫n la moneda del usuario.
   - Incluye desglose de costos: alojamiento, comida, transporte, actividades, etc.

4. S√© entusiasta, profesional y detallado en cada secci√≥n.
5. Usa emojis apropiados para hacer la informaci√≥n m√°s atractiva.
6. Aseg√∫rate de incluir TODAS las 5 secciones en tu respuesta.
7. Si detectas que est√°s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y contin√∫a en espa√±ol."""

# System Prompt para Gemini - Chat Conversacional
# Instrucci√≥n de sistema para preguntas de seguimiento en el chat
SYSTEM_INSTRUCTION_CHAT = """Eres Alex, el consultor de viajes m√°s experto y entusiasta del mundo.

REGLAS DE ORO:
1. RESPONDER √öNICAMENTE EN ESPA√ëOL. Nunca uses otros idiomas como Hindi, Ingl√©s, Franc√©s, etc. Todo el contenido debe estar en espa√±ol.
2. Tu respuesta debe usar formato Markdown para mejorar la legibilidad.
3. Responde de manera NATURAL y CONVERSACIONAL. No fuerces estructuras r√≠gidas.
4. Si el usuario hace una pregunta espec√≠fica (ej: "¬øEs seguro?", "¬øQu√© restaurantes recomiendas?"), responde directamente a esa pregunta de forma clara y detallada.
5. Solo usa las secciones estructuradas (üè® ALOJAMIENTO, ü•ò GASTRONOM√çA, etc.) si el usuario expl√≠citamente pide un "plan completo" o "plan de viaje". Para preguntas de seguimiento, responde de forma conversacional.
6. S√© entusiasta, profesional y detallado.
7. Usa emojis apropiados cuando sea natural, pero no fuerces su uso.
8. Si detectas que est√°s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y contin√∫a en espa√±ol.
9. Mant√©n el contexto del viaje que el usuario est√° planificando."""


class GeminiService:
    """Servicio para interactuar con Google Gemini API."""
    
    def __init__(self):
        """Inicializa el servicio de Gemini y valida la API key."""
        self.api_key = os.getenv("GEMINI_API_KEY")
        
        if not self.api_key:
            raise ValueError(
                "‚ùå ERROR: GEMINI_API_KEY no encontrada en variables de entorno. "
                "Por favor, crea un archivo .env con tu API key de Google Gemini."
            )
        
        # Configurar la API key
        genai.configure(api_key=self.api_key)
        
        # Inicializar el modelo usando gemini-2.0-flash (gemini-1.5-flash no est√° disponible)
        # Configuraci√≥n del modelo usando os.getenv para la API Key (ya configurada arriba)
        try:
            self.model = genai.GenerativeModel(model_name='gemini-2.0-flash')
            logger.info("‚úÖ Servicio de Gemini inicializado correctamente con gemini-2.0-flash")
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar el modelo de Gemini: {e}")
            raise
    
    def generate_travel_recommendation(
        self, 
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = "",
        user_currency: str = "USD"
    ) -> str:
        """
        Genera una recomendaci√≥n de viaje usando Gemini con campos estructurados.
        
        Args:
            destination: El destino del viaje (obligatorio)
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            user_currency: Moneda del usuario para conversi√≥n (opcional, default: USD)
            
        Returns:
            str: Recomendaci√≥n de viaje formateada en Markdown con las 5 secciones estrictas
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Validar argumentos antes de construir el prompt
            if not destination or not destination.strip():
                raise ValueError("El destino no puede estar vac√≠o")
            
            destination = destination.strip()
            date = date.strip() if date else ""
            budget = budget.strip() if budget else ""
            style = style.strip() if style else ""
            user_currency = user_currency.strip() if user_currency else "USD"
            
            logger.info(f"üì§ Generando recomendaci√≥n de viaje - Destino: '{destination}', Fecha: '{date}', Presupuesto: '{budget}', Estilo: '{style}', Moneda: '{user_currency}'")
            
            # Construir el prompt combinando los 4 campos en una frase coherente
            prompt_parts = [f"Planifica un viaje a {destination}"]
            
            if date:
                prompt_parts.append(f"para la fecha {date}")
            
            if budget:
                prompt_parts.append(f"con presupuesto {budget}")
            
            if style:
                prompt_parts.append(f"y estilo {style}")
            
            # Combinar todas las partes en una frase coherente
            user_request = " ".join(prompt_parts) + "."
            
            # Agregar instrucci√≥n sobre moneda si no es USD
            currency_instruction = ""
            if user_currency and user_currency.upper() != "USD":
                currency_instruction = f"\n\nIMPORTANTE: El usuario prefiere ver los costos en su moneda local ({user_currency}). En la secci√≥n 'üí∞ ESTIMACI√ìN DE COSTOS', proporciona los valores en USD y tambi√©n incluye la conversi√≥n aproximada a {user_currency}. Ejemplo: '$100 USD (~400,000 {user_currency})'."
            
            # Construir el prompt completo incluyendo el system instruction para PLAN
            # La instrucci√≥n de sistema se inyecta antes de la pregunta del usuario
            full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}{currency_instruction}\n\n---\n\nSolicitud del usuario: {user_request}"
            
            # Generar respuesta usando Gemini
            # Esta es la llamada a la API de Google Gemini que env√≠a la pregunta del usuario
            logger.info(f"üîÑ Enviando solicitud a Gemini: {user_request[:100]}...")
            logger.debug(f"üìù Longitud del prompt completo: {len(full_prompt)} caracteres")
            
            response = self.model.generate_content(full_prompt)
            
            # Extraer el texto de la respuesta
            if not response or not hasattr(response, 'text') or not response.text:
                raise ValueError("La respuesta de Gemini est√° vac√≠a o no tiene texto")
            
            recommendation = response.text
            
            logger.info(f"‚úÖ Recomendaci√≥n generada exitosamente por Alex ({len(recommendation)} caracteres)")
            return recommendation
            
        except ValueError as e:
            # Errores de validaci√≥n o configuraci√≥n
            logger.error(f"‚ùå Error de validaci√≥n en Gemini: {e}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraci√≥n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"‚ùå Error al consultar Gemini: {error_type}: {error_message}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"üîç Argumentos recibidos: destination='{destination}', date='{date}', budget='{budget}', style='{style}'")
            raise Exception("Ocurri√≥ un error consultando a la IA")
    
    def generate_chat_response(
        self,
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = "",
        message: str = "",
        history: List[Dict] = []
    ) -> str:
        """
        Genera una respuesta de chat usando Gemini con memoria conversacional.
        
        Esta funci√≥n inyecta el contexto del viaje (destino, fecha, presupuesto, estilo) y
        la personalidad de Alex (consultor de viajes experto y entusiasta) mediante un
        system prompt especializado para conversaciones (SYSTEM_INSTRUCTION_CHAT).
        
        El historial de conversaci√≥n se limita a los √∫ltimos 6 mensajes para optimizar
        el uso de tokens y mantener el contexto relevante. Si hay historial, se construye
        un prompt que incluye el contexto del viaje, el historial de conversaci√≥n y el
        nuevo mensaje del usuario. Si no hay historial, se trata como una solicitud inicial
        y se usa SYSTEM_INSTRUCTION_PLAN.
        
        Args:
            destination: El destino del viaje
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            message: El nuevo mensaje del usuario
            history: Lista de mensajes anteriores en formato [{"role": "user", "parts": "..."}, ...]
            
        Returns:
            str: Respuesta de Gemini formateada en Markdown
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Construir el contexto del viaje
            context_info = f"Contexto del viaje: Destino: {destination}"
            if date:
                context_info += f", Fecha: {date}"
            if budget:
                context_info += f", Presupuesto: {budget}"
            if style:
                context_info += f", Estilo: {style}"
            
            # Si hay historial, construir el prompt con el historial concatenado
            if history:
                # Construir el historial como texto para el contexto
                history_text = "\n\n--- Historial de Conversaci√≥n ---\n\n"
                for msg in history:
                    role_label = "Usuario" if msg.get("role") == "user" else "Alex"
                    history_text += f"{role_label}: {msg.get('parts', '')}\n\n"
                
                # Construir el prompt completo con historial usando SYSTEM_INSTRUCTION_CHAT
                # Para preguntas de seguimiento, usa la instrucci√≥n conversacional
                full_prompt = f"{SYSTEM_INSTRUCTION_CHAT}\n\n---\n\n{context_info}\n\n{history_text}---\n\nUsuario pregunta ahora: {message}"
                
                logger.info(f"Enviando mensaje de chat a Gemini con historial de {len(history)} mensajes")
            else:
                # Si no hay historial, es el primer mensaje - usar SYSTEM_INSTRUCTION_PLAN
                prompt_parts = [f"Planifica un viaje a {destination}"]
                
                if date:
                    prompt_parts.append(f"para la fecha {date}")
                
                if budget:
                    prompt_parts.append(f"con presupuesto {budget}")
                
                if style:
                    prompt_parts.append(f"y estilo {style}")
                
                user_request = " ".join(prompt_parts) + "."
                full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}\n\n---\n\n{context_info}\n\nSolicitud del usuario: {user_request}"
                
                logger.info(f"Enviando solicitud inicial a Gemini: {destination}")
            
            # Generar respuesta usando Gemini
            response = self.model.generate_content(full_prompt)
            recommendation = response.text
            logger.info("‚úÖ Respuesta generada exitosamente por Alex")
            return recommendation
            
        except ValueError as e:
            # Errores de validaci√≥n o configuraci√≥n
            logger.error(f"‚ùå Error de validaci√≥n en Gemini (chat): {e}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraci√≥n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"‚ùå Error al consultar Gemini (chat): {error_type}: {error_message}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"üîç Argumentos recibidos: destination='{destination}', message='{message[:50]}...', history_length={len(history)}")
            raise Exception("Ocurri√≥ un error consultando a la IA")


# Instancia global del servicio (se inicializa al importar)
_gemini_service: Optional[GeminiService] = None


def get_gemini_service() -> GeminiService:
    """
    Obtiene la instancia singleton del servicio de Gemini.
    
    Returns:
        GeminiService: Instancia del servicio
    """
    global _gemini_service
    
    if _gemini_service is None:
        _gemini_service = GeminiService()
    
    return _gemini_service

