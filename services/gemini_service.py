"""
Servicio de integraci√≥n con Google Gemini para recomendaciones de viaje.
"""
import os
import logging
import traceback
import re
from typing import Optional, List, Dict, Tuple
import google.generativeai as genai
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logger = logging.getLogger(__name__)


def sanitize_input(text: str, max_length: int = 500) -> Tuple[bool, str]:
    """
    Sanitiza y valida el input del usuario para prevenir prompt injection.
    
    Esta funci√≥n detecta patrones maliciosos comunes en intentos de prompt injection
    y valida la longitud del input para prevenir payloads gigantes.
    
    Args:
        text: Texto a sanitizar
        max_length: Longitud m√°xima permitida (default: 500 caracteres)
        
    Returns:
        Tuple[bool, str]: (es_v√°lido, mensaje_error)
        - Si es_v√°lido es True, el texto es seguro
        - Si es_v√°lido es False, mensaje_error contiene la raz√≥n del rechazo
    """
    if not text or not isinstance(text, str):
        return False, "El texto no puede estar vac√≠o"
    
    # Normalizar el texto (min√∫sculas para comparaci√≥n case-insensitive)
    text_lower = text.lower().strip()
    
    # Verificar longitud m√°xima
    if len(text) > max_length:
        return False, f"El texto excede la longitud m√°xima permitida de {max_length} caracteres"
    
    # Patrones maliciosos comunes de prompt injection (ingl√©s y espa√±ol)
    malicious_patterns = [
        # Intentos de ignorar instrucciones (ingl√©s)
        r"(?i)ignore\s+(your|all|previous|earlier|prior)\s+(instructions?|prompts?|rules?|directives?|guidelines?)",
        r"(?i)forget\s+(everything|all|previous|earlier|prior)",
        r"(?i)disregard\s+(your|all|previous|earlier)\s+(instructions?|prompts?|rules?)",
        r"(?i)override\s+(your|system|previous)\s+(instructions?|prompts?|rules?)",
        r"(?i)ignore\s+(your|all|previous|earlier|prior)",
        # Intentos de ignorar instrucciones (espa√±ol)
        r"(?i)ignora\s+(tus|todas|las|tus\s+instrucciones|tus\s+reglas)",
        r"(?i)olvida\s+(todo|todas|las|tus|instrucciones)",
        r"(?i)desobedece\s+(tus|las|instrucciones|reglas)",
        r"(?i)anula\s+(tus|las|instrucciones|reglas)",
        
        # Intentos de cambiar el rol o comportamiento (ingl√©s)
        r"(?i)you\s+are\s+now\s+(a|an|the)",
        r"(?i)act\s+as\s+(if\s+)?(you\s+are\s+)?(a|an|the)",
        r"(?i)pretend\s+(to\s+be|you\s+are|that\s+you)",
        r"(?i)roleplay\s+(as|that)",
        # Intentos de cambiar el rol o comportamiento (espa√±ol)
        r"(?i)eres\s+ahora\s+(un|una|el|la)",
        r"(?i)act√∫a\s+(como|si\s+eres|si\s+fu eras)",
        r"(?i)finge\s+(ser|que\s+eres|que)",
        r"(?i)hazte\s+pasar\s+por",
        
        # Intentos de acceso a instrucciones del sistema (ingl√©s)
        r"(?i)system\s*:",
        r"(?i)system\s+prompt",
        r"(?i)system\s+instruction",
        r"(?i)assistant\s*:",
        r"(?i)ai\s+instruction",
        # Intentos de acceso a instrucciones del sistema (espa√±ol)
        r"(?i)sistema\s*:",
        r"(?i)prompt\s+del\s+sistema",
        r"(?i)instrucciones\s+del\s+sistema",
        r"(?i)asistente\s*:",
        r"(?i)mu√©strame\s+(tus|las|el)\s+(instrucciones|prompt|reglas)",
        
        # Intentos de extraer informaci√≥n del sistema
        r"(?i)show\s+(me\s+)?(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)what\s+(are\s+)?(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)reveal\s+(your|the)\s+(instructions|prompt|system|rules)",
        r"(?i)print\s+(your|the)\s+(instructions|prompt|system|rules)",
        
        # Intentos de ejecutar comandos
        r"(?i)(execute|run|eval|exec)\s*[:(]",
        r"(?i)<script",
        r"(?i)javascript\s*:",
        
        # Intentos de inyecci√≥n de c√≥digo
        r"(?i)(import|from)\s+\w+\s+import",
        r"(?i)__import__",
        r"(?i)subprocess",
    ]
    
    # Verificar cada patr√≥n
    for pattern in malicious_patterns:
        if re.search(pattern, text_lower):
            logger.warning(f"‚ö†Ô∏è  Intento de prompt injection detectado: {text[:100]}...")
            return False, "El contenido contiene patrones no permitidos. Por favor, reformula tu solicitud."
    
    # Si pasa todas las validaciones, el texto es seguro
    return True, ""

# System Prompt para Gemini - Plan Inicial de Viaje
# Instrucci√≥n de sistema para cuando el usuario solicita un plan completo de viaje
SYSTEM_INSTRUCTION_PLAN = """Eres Alex, un experto Travel Curator con el estilo de escritura de Lonely Planet y Cond√© Nast Traveler. Tu misi√≥n es crear planes de viaje evocativos, personalizados y visualmente atractivos.

REGLAS FUNDAMENTALES:
1. RESPONDER √öNICAMENTE EN ESPA√ëOL. Nunca uses otros idiomas. Todo el contenido debe estar en espa√±ol.
2. Tu respuesta SIEMPRE debe usar formato Markdown.
3. TONO Y ESTILO:
   - Escribe como un experto Travel Curator: evocativo pero conciso.
   - No solo listes caracter√≠sticas; explica el *vibe* y la experiencia.
   - SIEMPRE referencia el presupuesto y estilo del usuario en tus descripciones.
   - Ejemplos: "Perfecto para tu presupuesto de mochilero porque...", "Ideal para tu estilo cultural ya que...", "Alineado con tu presupuesto de lujo debido a..."
   - S√© personal y conecta cada recomendaci√≥n con las preferencias del usuario.

4. INTRODUCCI√ìN OBLIGATORIA:
   ‚ö†Ô∏è ANTES de la primera secci√≥n (## üè® ALOJAMIENTO), SIEMPRE incluye un mensaje introductorio personal y evocativo.
   ‚ö†Ô∏è Este mensaje debe:
      - Ser de 2-4 oraciones m√°ximo
      - Conectar con el destino, presupuesto y estilo del usuario
      - Crear expectativa y entusiasmo
      - Ser personal y directo (usar "tu", "te", "vas a")
   ‚ö†Ô∏è Ejemplo: "¬°Absolutamente! Prepar√©monos para explorar la vibrante Bogot√°, conectando con su rica historia y cultura, todo dentro de tu presupuesto de mochilero. Esta ciudad te espera con experiencias aut√©nticas que deleitar√°n tus sentidos sin vaciar tu bolsillo."
   ‚ö†Ô∏è NO empieces directamente con "## üè® ALOJAMIENTO". SIEMPRE incluye este mensaje introductorio primero.

5. FORMATO ESTRICTO DE SECCIONES:
   - Separa cada secci√≥n claramente con un salto de l√≠nea doble.
   - Usa EXACTAMENTE estos encabezados: '## üè® ALOJAMIENTO', '## ü•ò GASTRONOM√çA', '## üíé LUGARES', '## üí° CONSEJOS', '## üí∞ COSTOS'.
   - Despu√©s de cada encabezado, escribe UNA l√≠nea introductoria corta, personal y evocativa (1-2 oraciones m√°ximo).
   - Luego deja un salto de l√≠nea simple antes de la lista.

6. Tu respuesta DEBE tener EXACTAMENTE estas 5 secciones en este orden:

## üè® ALOJAMIENTO
[L√≠nea introductoria corta y personal sobre el alojamiento en este destino]

## ü•ò GASTRONOM√çA
[L√≠nea introductoria corta sobre la escena gastron√≥mica]

## üíé LUGARES
[L√≠nea introductoria corta sobre qu√© ver y hacer]

## üí° CONSEJOS
[L√≠nea introductoria corta con tips generales]

## üí∞ COSTOS
[L√≠nea introductoria corta sobre el presupuesto]
   - ‚ö†Ô∏è REGLA CR√çTICA: TODOS los costos DEBEN estar en PESOS COLOMBIANOS (COP) como moneda principal.
   - Formato obligatorio para COP: "$150.000 COP" o "$2.500.000 COP" (usa punto como separador de miles).
   - Para destinos internacionales, opcionalmente muestra la moneda local en par√©ntesis: "$450.000 COP (~$100 EUR)".
   - El precio en COP debe ser el DESTACADO y principal; la moneda local es solo referencia.
   - Incluye desglose de costos: alojamiento, comida, transporte, actividades, etc.
   - Todos los precios espec√≠ficos (hoteles, restaurantes, entradas) deben estar en COP.

7. FORMATO DE LISTAS - REGLA CR√çTICA (NO NEGOCIABLE):
   ‚ö†Ô∏è Cada √≠tem de lista DEBE usar este formato EXACTO:
   `* **Nombre del Lugar/Hotel/Restaurante**: Descripci√≥n evocativa que explique el vibe y conecte con el presupuesto/estilo del usuario.`
   
   ‚ö†Ô∏è Los `**` son OBLIGATORIOS para que el nombre aparezca en negrita en Markdown.
   
   ‚ö†Ô∏è Si incluyes precios en las descripciones, DEBEN estar en COP con formato: "$150.000 COP" o "$2.500.000 COP".
   ‚ö†Ô∏è Para destinos internacionales, puedes agregar la moneda local en par√©ntesis: "$450.000 COP (~$100 EUR)".
   
   ‚ö†Ô∏è Ejemplo CORRECTO:
   * **Hotel Boutique El Jard√≠n**: Un refugio √≠ntimo en el coraz√≥n hist√≥rico desde $180.000 COP/noche, perfecto para tu presupuesto moderado. Sus habitaciones con balcones coloniales y el desayuno con vista a la plaza te har√°n sentir como un local privilegiado.
   
   * **Hostal Backpacker's Paradise**: La vibra mochilera definitiva desde $45.000 COP/noche. Con tu presupuesto ajustado, aqu√≠ encontrar√°s camas limpias, cocina compartida y el mejor ambiente social para conocer viajeros de todo el mundo.
   
   ‚ö†Ô∏è Ejemplo INCORRECTO (NUNCA hagas esto):
   ‚Ä¢ Hotel A: Tiene wifi, piscina y est√° cerca del centro.
   Hotel B es un lugar maravilloso con muchas caracter√≠sticas...
   ‚Ä¢ Hotel C: $100 USD por noche (NO uses USD como moneda principal)
   
   ‚ö†Ô∏è NO uses bullets simples (‚Ä¢). USA SIEMPRE el formato `* **Nombre**: Descripci√≥n`.

8. ESTRUCTURA COMPLETA DE EJEMPLO:
¬°Absolutamente! Prepar√©monos para explorar la vibrante [Destino], conectando con su rica historia y cultura, todo dentro de tu presupuesto de [presupuesto]. Esta ciudad te espera con experiencias aut√©nticas que deleitar√°n tus sentidos sin vaciar tu bolsillo.

## üè® ALOJAMIENTO

En [Destino], encontrar√°s opciones que van desde hostales con alma hasta hoteles boutique que capturan la esencia local.

* **Hotel Boutique El Jard√≠n**: [Descripci√≥n evocativa con referencia a presupuesto/estilo]
* **Hostal Backpacker's Paradise**: [Descripci√≥n evocativa con referencia a presupuesto/estilo]

## ü•ò GASTRONOM√çA

[L√≠nea introductoria corta sobre la comida local]

* **Restaurante La Esquina**: [Descripci√≥n evocativa con referencia a presupuesto/estilo]
* **Mercado de Sabores**: [Descripci√≥n evocativa con referencia a presupuesto/estilo]

9. RECUERDA:
   - Cada secci√≥n debe tener UNA l√≠nea introductoria corta (1-2 oraciones) antes de la lista.
   - Cada √≠tem de lista DEBE usar `* **Nombre**: Descripci√≥n` con los `**` para negrita.
   - SIEMPRE conecta las recomendaciones con el presupuesto y estilo del usuario.
   - S√© evocativo: describe sensaciones, vibes, experiencias, no solo caracter√≠sticas.
   - Mant√©n los encabezados exactamente como se especifican con los emojis.
   - Si detectas que est√°s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y contin√∫a en espa√±ol."""

# System Prompt para Gemini - Chat Conversacional
# Instrucci√≥n de sistema para preguntas de seguimiento en el chat
SYSTEM_INSTRUCTION_CHAT = """Eres Alex, el consultor de viajes m√°s experto y entusiasta del mundo.

REGLAS DE ORO:
1. RESPONDER √öNICAMENTE EN ESPA√ëOL. Nunca uses otros idiomas como Hindi, Ingl√©s, Franc√©s, etc. Todo el contenido debe estar en espa√±ol.
2. Tu respuesta debe usar formato Markdown para mejorar la legibilidad.
3. Responde de manera NATURAL y CONVERSACIONAL. No fuerces estructuras r√≠gidas.
4. Si el usuario hace una pregunta espec√≠fica (ej: "¬øEs seguro?", "¬øQu√© restaurantes recomiendas?"), responde directamente a esa pregunta de forma clara y detallada.
5. Solo usa las secciones estructuradas (üè® ALOJAMIENTO, ü•ò GASTRONOM√çA, etc.) si el usuario expl√≠citamente pide un "plan completo" o "plan de viaje". Para preguntas de seguimiento, responde de forma conversacional.
6. S√© entusiasta, profesional y detallado.
7. Usa emojis apropiados cuando sea natural, pero no fuerces su uso.
8. Si detectas que est√°s escribiendo en otro idioma, DETENTE INMEDIATAMENTE y contin√∫a en espa√±ol.
9. Mant√©n el contexto del viaje que el usuario est√° planificando."""


class GeminiService:
    """Servicio para interactuar con Google Gemini API."""
    
    def __init__(self):
        """Inicializa el servicio de Gemini y valida la API key."""
        self.api_key = os.getenv("GEMINI_API_KEY")
        
        if not self.api_key:
            raise ValueError(
                "‚ùå ERROR: GEMINI_API_KEY no encontrada en variables de entorno. "
                "Por favor, crea un archivo .env con tu API key de Google Gemini."
            )
        
        # Configurar la API key
        genai.configure(api_key=self.api_key)
        
        # Inicializar el modelo usando gemini-2.0-flash con configuraci√≥n avanzada
        # Configuraci√≥n del modelo con l√≠mites de tokens y temperatura
        try:
            # Configuraci√≥n de generaci√≥n con l√≠mites de tokens y temperatura
            # max_output_tokens: 2048 - L√≠mite m√°ximo de tokens en la respuesta generada.
            #   Controla la longitud m√°xima de la salida. Un token ‚âà 4 caracteres en espa√±ol.
            #   Con 2048 tokens, la respuesta puede tener aproximadamente 8000 caracteres.
            #   Esto previene respuestas excesivamente largas y controla costos.
            #
            # temperature: 0.7 - Controla la creatividad vs precisi√≥n de las respuestas.
            #   Rango: 0.0 (muy determinista, repetitivo) a 1.0 (muy creativo, variado).
            #   Con 0.7, obtenemos un balance entre creatividad y coherencia:
            #   - Respuestas creativas pero coherentes
            #   - Variedad en las recomendaciones sin perder precisi√≥n
            #   - Ideal para consultor√≠a de viajes donde queremos sugerencias √∫nicas pero √∫tiles
            generation_config = {
                "max_output_tokens": 2048,
                "temperature": 0.7
            }
            
            self.model = genai.GenerativeModel(
                model_name='gemini-2.0-flash',
                generation_config=generation_config
            )
            logger.info("‚úÖ Servicio de Gemini inicializado correctamente con gemini-2.0-flash")
            logger.info("‚öôÔ∏è  Configuraci√≥n: max_output_tokens=2048, temperature=0.7")
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar el modelo de Gemini: {e}")
            raise
    
    def generate_travel_recommendation(
        self, 
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = "",
        user_currency: str = "COP"
    ) -> Tuple[str, str]:
        """
        Genera una recomendaci√≥n de viaje usando Gemini con campos estructurados.
        
        Args:
            destination: El destino del viaje (obligatorio)
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            user_currency: Moneda del usuario (opcional, default: COP para usuarios colombianos)
            
        Returns:
            Tuple[str, str]: (recomendaci√≥n, finish_reason)
            - recomendaci√≥n: Recomendaci√≥n de viaje formateada en Markdown con las 5 secciones estrictas
            - finish_reason: Raz√≥n de finalizaci√≥n de la generaci√≥n ("STOP", "MAX_TOKENS", etc.)
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Validar argumentos antes de construir el prompt
            if not destination or not destination.strip():
                raise ValueError("El destino no puede estar vac√≠o")
            
            destination = destination.strip()
            date = date.strip() if date else ""
            budget = budget.strip() if budget else ""
            style = style.strip() if style else ""
            user_currency = user_currency.strip() if user_currency else "COP"
            
            logger.info(f"üì§ Generando recomendaci√≥n de viaje - Destino: '{destination}', Fecha: '{date}', Presupuesto: '{budget}', Estilo: '{style}', Moneda: '{user_currency}'")
            
            # Construir el prompt combinando los 4 campos en una frase coherente
            prompt_parts = [f"Planifica un viaje a {destination}"]
            
            if date:
                prompt_parts.append(f"para la fecha {date}")
            
            if budget:
                prompt_parts.append(f"con presupuesto {budget}")
            
            if style:
                prompt_parts.append(f"y estilo {style}")
            
            # Combinar todas las partes en una frase coherente
            user_request = " ".join(prompt_parts) + "."
            
            # Construir contexto destacado de presupuesto y estilo para que Gemini los referencia expl√≠citamente
            context_highlight = ""
            if budget or style:
                context_highlight = "\n\n--- CONTEXTO DEL USUARIO (REFERENCIA ESTO EN CADA RECOMENDACI√ìN) ---\n"
                if budget:
                    context_highlight += f"‚Ä¢ Presupuesto del usuario: {budget}\n"
                    context_highlight += "  ‚Üí IMPORTANTE: En cada recomendaci√≥n, explica POR QU√â es perfecta para este presupuesto.\n"
                if style:
                    context_highlight += f"‚Ä¢ Estilo de viaje del usuario: {style}\n"
                    context_highlight += "  ‚Üí IMPORTANTE: En cada recomendaci√≥n, conecta la experiencia con este estilo de viaje.\n"
                context_highlight += "\nEjemplo de c√≥mo referenciar: 'Perfecto para tu presupuesto de mochilero porque...' o 'Ideal para tu estilo cultural ya que...'\n"
            
            # Instrucci√≥n obligatoria sobre moneda: La aplicaci√≥n est√° dirigida a usuarios colombianos
            # Todos los costos deben estar en COP como moneda principal
            currency_instruction = "\n\n--- REGLAS DE MONEDA (OBLIGATORIO) ---\n"
            currency_instruction += "‚ö†Ô∏è TODOS los costos DEBEN estar en PESOS COLOMBIANOS (COP) como moneda PRINCIPAL.\n"
            currency_instruction += "‚Ä¢ Formato obligatorio: '$150.000 COP' o '$2.500.000 COP' (usa punto como separador de miles).\n"
            currency_instruction += "‚Ä¢ Para destinos internacionales, opcionalmente muestra la moneda local en par√©ntesis: '$450.000 COP (~$100 EUR)'.\n"
            currency_instruction += "‚Ä¢ El precio en COP debe ser el DESTACADO y principal; la moneda local es solo referencia.\n"
            currency_instruction += "‚Ä¢ Esto aplica a TODOS los precios: hoteles, restaurantes, entradas, transporte, actividades.\n"
            currency_instruction += "‚Ä¢ La secci√≥n 'üí∞ COSTOS' DEBE seguir esta regla estrictamente.\n"
            
            # Construir el prompt completo incluyendo el system instruction para PLAN
            # La instrucci√≥n de sistema se inyecta antes de la pregunta del usuario
            full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}{context_highlight}{currency_instruction}\n\n---\n\nSolicitud del usuario: {user_request}"
            
            # Generar respuesta usando Gemini
            # Esta es la llamada a la API de Google Gemini que env√≠a la pregunta del usuario
            logger.info(f"üîÑ Enviando solicitud a Gemini: {user_request[:100]}...")
            logger.debug(f"üìù Longitud del prompt completo: {len(full_prompt)} caracteres")
            
            response = self.model.generate_content(full_prompt)
            
            # Extraer el texto de la respuesta
            if not response or not hasattr(response, 'text') or not response.text:
                raise ValueError("La respuesta de Gemini est√° vac√≠a o no tiene texto")
            
            recommendation = response.text
            
            # Extraer finish_reason para detectar si la respuesta fue cortada
            finish_reason = "STOP"  # Valor por defecto
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    finish_reason_raw = candidate.finish_reason
                    # Manejar diferentes tipos de finish_reason (enum, string, n√∫mero)
                    if finish_reason_raw is None:
                        finish_reason = "STOP"
                    elif hasattr(finish_reason_raw, 'name'):  # Es un enum
                        finish_reason = finish_reason_raw.name
                    elif hasattr(finish_reason_raw, 'value'):  # Es un enum con value
                        finish_reason = str(finish_reason_raw.value)
                    else:
                        finish_reason = str(finish_reason_raw)
                    
                    # Normalizar valores comunes
                    finish_reason_upper = finish_reason.upper()
                    if "STOP" in finish_reason_upper or finish_reason == "1" or finish_reason == 1:
                        finish_reason = "STOP"
                    elif "MAX_TOKENS" in finish_reason_upper or "LENGTH" in finish_reason_upper or finish_reason == "2" or finish_reason == 2:
                        finish_reason = "MAX_TOKENS"
                    elif "SAFETY" in finish_reason_upper or finish_reason == "3" or finish_reason == 3:
                        finish_reason = "SAFETY"
                    elif "RECITATION" in finish_reason_upper or finish_reason == "4" or finish_reason == 4:
                        finish_reason = "RECITATION"
                    
                    if finish_reason != "STOP":
                        logger.warning(f"‚ö†Ô∏è  Respuesta cortada: finish_reason={finish_reason}")
            
            logger.info(f"‚úÖ Recomendaci√≥n generada exitosamente por Alex ({len(recommendation)} caracteres, finish_reason={finish_reason})")
            return recommendation, finish_reason
            
        except ValueError as e:
            # Errores de validaci√≥n o configuraci√≥n
            logger.error(f"‚ùå Error de validaci√≥n en Gemini: {e}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraci√≥n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"‚ùå Error al consultar Gemini: {error_type}: {error_message}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"üîç Argumentos recibidos: destination='{destination}', date='{date}', budget='{budget}', style='{style}'")
            raise Exception("Ocurri√≥ un error consultando a la IA")
    
    def generate_chat_response(
        self,
        destination: str,
        date: str = "",
        budget: str = "",
        style: str = "",
        message: str = "",
        history: List[Dict] = []
    ) -> Tuple[str, str]:
        """
        Genera una respuesta de chat usando Gemini con memoria conversacional.
        
        Esta funci√≥n inyecta el contexto del viaje (destino, fecha, presupuesto, estilo) y
        la personalidad de Alex (consultor de viajes experto y entusiasta) mediante un
        system prompt especializado para conversaciones (SYSTEM_INSTRUCTION_CHAT).
        
        El historial de conversaci√≥n se limita a los √∫ltimos 10 mensajes para optimizar
        el uso de tokens de entrada y mantener el contexto relevante. Esto reduce los costos
        de API al enviar solo el contexto m√°s reciente necesario para la conversaci√≥n.
        Si hay historial, se construye un prompt que incluye el contexto del viaje, el
        historial de conversaci√≥n y el nuevo mensaje del usuario. Si no hay historial, se
        trata como una solicitud inicial y se usa SYSTEM_INSTRUCTION_PLAN.
        
        Args:
            destination: El destino del viaje
            date: La fecha del viaje (opcional)
            budget: El presupuesto del viaje (opcional)
            style: El estilo de viaje (opcional)
            message: El nuevo mensaje del usuario
            history: Lista de mensajes anteriores en formato [{"role": "user", "parts": "..."}, ...]
            
        Returns:
            Tuple[str, str]: (respuesta, finish_reason)
            - respuesta: Respuesta de Gemini formateada en Markdown
            - finish_reason: Raz√≥n de finalizaci√≥n de la generaci√≥n ("STOP", "MAX_TOKENS", etc.)
            
        Raises:
            Exception: Si hay un error al comunicarse con Gemini
        """
        try:
            # Construir el contexto del viaje
            context_info = f"Contexto del viaje: Destino: {destination}"
            if date:
                context_info += f", Fecha: {date}"
            if budget:
                context_info += f", Presupuesto: {budget}"
            if style:
                context_info += f", Estilo: {style}"
            
            # Si hay historial, construir el prompt con el historial concatenado
            # Gesti√≥n de Historial: Limitar a los √∫ltimos 10 mensajes para ahorrar tokens de entrada
            # Esto reduce significativamente el costo de cada llamada a la API al enviar
            # solo el contexto m√°s reciente necesario para mantener la coherencia conversacional.
            if history:
                # Limitar el historial a los √∫ltimos 10 mensajes
                limited_history = history[-10:] if len(history) > 10 else history
                if len(history) > 10:
                    logger.info(f"üìö Historial limitado a {len(limited_history)} mensajes (de {len(history)} totales) para optimizar tokens")
                
                # Construir el historial como texto para el contexto
                history_text = "\n\n--- Historial de Conversaci√≥n ---\n\n"
                for msg in limited_history:
                    role_label = "Usuario" if msg.get("role") == "user" else "Alex"
                    history_text += f"{role_label}: {msg.get('parts', '')}\n\n"
                
                # Construir el prompt completo con historial usando SYSTEM_INSTRUCTION_CHAT
                # Para preguntas de seguimiento, usa la instrucci√≥n conversacional
                full_prompt = f"{SYSTEM_INSTRUCTION_CHAT}\n\n---\n\n{context_info}\n\n{history_text}---\n\nUsuario pregunta ahora: {message}"
                
                logger.info(f"Enviando mensaje de chat a Gemini con historial de {len(limited_history)} mensajes")
            else:
                # Si no hay historial, es el primer mensaje - usar SYSTEM_INSTRUCTION_PLAN
                prompt_parts = [f"Planifica un viaje a {destination}"]
                
                if date:
                    prompt_parts.append(f"para la fecha {date}")
                
                if budget:
                    prompt_parts.append(f"con presupuesto {budget}")
                
                if style:
                    prompt_parts.append(f"y estilo {style}")
                
                user_request = " ".join(prompt_parts) + "."
                full_prompt = f"{SYSTEM_INSTRUCTION_PLAN}\n\n---\n\n{context_info}\n\nSolicitud del usuario: {user_request}"
                
                logger.info(f"Enviando solicitud inicial a Gemini: {destination}")
            
            # Generar respuesta usando Gemini
            response = self.model.generate_content(full_prompt)
            recommendation = response.text
            
            # Extraer finish_reason para detectar si la respuesta fue cortada
            finish_reason = "STOP"  # Valor por defecto
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    finish_reason_raw = candidate.finish_reason
                    # Manejar diferentes tipos de finish_reason (enum, string, n√∫mero)
                    if finish_reason_raw is None:
                        finish_reason = "STOP"
                    elif hasattr(finish_reason_raw, 'name'):  # Es un enum
                        finish_reason = finish_reason_raw.name
                    elif hasattr(finish_reason_raw, 'value'):  # Es un enum con value
                        finish_reason = str(finish_reason_raw.value)
                    else:
                        finish_reason = str(finish_reason_raw)
                    
                    # Normalizar valores comunes
                    finish_reason_upper = finish_reason.upper()
                    if "STOP" in finish_reason_upper or finish_reason == "1" or finish_reason == 1:
                        finish_reason = "STOP"
                    elif "MAX_TOKENS" in finish_reason_upper or "LENGTH" in finish_reason_upper or finish_reason == "2" or finish_reason == 2:
                        finish_reason = "MAX_TOKENS"
                    elif "SAFETY" in finish_reason_upper or finish_reason == "3" or finish_reason == 3:
                        finish_reason = "SAFETY"
                    elif "RECITATION" in finish_reason_upper or finish_reason == "4" or finish_reason == 4:
                        finish_reason = "RECITATION"
                    
                    if finish_reason != "STOP":
                        logger.warning(f"‚ö†Ô∏è  Respuesta cortada en chat: finish_reason={finish_reason}")
            
            logger.info(f"‚úÖ Respuesta generada exitosamente por Alex (finish_reason={finish_reason})")
            return recommendation, finish_reason
            
        except ValueError as e:
            # Errores de validaci√≥n o configuraci√≥n
            logger.error(f"‚ùå Error de validaci√≥n en Gemini (chat): {e}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            raise Exception(f"Error de configuraci√≥n: {e}")
            
        except Exception as e:
            # Bloque try/except con logging detallado
            error_type = type(e).__name__
            error_message = str(e)
            logger.error(f"‚ùå Error al consultar Gemini (chat): {error_type}: {error_message}")
            logger.error(f"üìã Traceback completo:\n{traceback.format_exc()}")
            logger.error(f"üîç Argumentos recibidos: destination='{destination}', message='{message[:50]}...', history_length={len(history)}")
            raise Exception("Ocurri√≥ un error consultando a la IA")


# Instancia global del servicio (se inicializa al importar)
_gemini_service: Optional[GeminiService] = None


def get_gemini_service() -> GeminiService:
    """
    Obtiene la instancia singleton del servicio de Gemini.
    
    Returns:
        GeminiService: Instancia del servicio
    """
    global _gemini_service
    
    if _gemini_service is None:
        _gemini_service = GeminiService()
    
    return _gemini_service

